{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import progressbar\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import truncexpon, poisson, norm\n",
    "from utils import *\n",
    "from gen_inputs import *\n",
    "from functs_inputs import *\n",
    "from sim_hLN import *\n",
    "from train_hLN import *\n",
    "from init_hLN import *\n",
    "\n",
    "matplotlib.rcParams[\"savefig.dpi\"] = 200\n",
    "matplotlib.rcParams[\"legend.frameon\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now begin training of complex models, attempting to produce figure similar to S2 in Ujfalussy paper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First step is to define a hierarchical clustering for the inputs - then they can be distributed correctly according to each hLN architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of lists for this maybe? e.g. the following:\n",
    "clusts = [[[[0, 1],[2]],[[3, 4],[5, 6]]],[[[7, 8],[9]],[[10, 11],[12]]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the different hLN architectures we will be using:\n",
    "\n",
    "# 1L\n",
    "Jc_1l = np.array([0])\n",
    "# 1N\n",
    "Jc_1n = [0]\n",
    "# 2N\n",
    "Jc_2n = [0, 1, 1]\n",
    "# 3N\n",
    "Jc_3n = [0, 1, 1, 2, 2, 3, 3]\n",
    "# 4N\n",
    "Jc_4n = [0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some realistic inputs\n",
    "X_tot = tf.convert_to_tensor(np.load('real_inputs.npy'), dtype=tf.float32)  # real inputs made earlier\n",
    "X_e = X_tot[:629] # 629 excitatory inputs, in 13 ensembles\n",
    "X_i = X_tot[629:] # 120 inhibitory inputs, also in 13 ensembles\n",
    "# remember 1st inhibitory inputs is the somatic input - must always go to root subunit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now derive Wce, Wci for each model from the Jcs\n",
    "# define how many excitatory/inhibitory cells in each of 13 ensembles\n",
    "esyn = [48, 58, 52, 34, 45, 39, 44, 68, 50, 62, 30, 60, 39]\n",
    "isyn = [11, 11, 9, 6, 8, 5, 8, 12, 11, 13, 6, 11, 8]\n",
    "n_e = np.sum(esyn)\n",
    "n_i = np.sum(isyn)\n",
    "\n",
    "def create_weights(Jc):\n",
    "    \"\"\"Function here to create the Wci and Wce list for different hLN architectures. For now put neuron ensembles \n",
    "    onto the same leaves, with the mapping determined by the clusts list. Remember the first inhibitory input\n",
    "    is somatic and should go to the root subunit\"\"\"\n",
    "    return\n",
    "\n",
    "# just do single unit now for demonstration\n",
    "Wce_1l = [np.arange(0, n_e, 1)] #all input excitatory neurons connected to root subunit\n",
    "Wci_1l = [np.arange(n_e, n_e + n_i, 1)] #all input inhibitory neurons connected to root subunit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise a known version each of the models to generate data with\n",
    "hln_1l = hLN_Model(Jc=Jc_1l, Wce=Wce_1l, Wci=Wci_1l, sig_on=tf.constant([False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate output data from realistic inputs - save this somewhere\n",
    "target_1l = hln_1l(X_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick one target to train all models for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise 1L model, and optimise for data\n",
    "hln_1l.randomise_parameters() #change parameters from ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise 1N model, optimise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise 2N model, optimise\n",
    "# need a new /updated procedure for going up levels in the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise 3N model, optimise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise 4N model, optimise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
