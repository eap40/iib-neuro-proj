{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to build training up from simplest case to real, eventually producing Figure S3 from Ujfalussy paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import truncexpon, poisson, norm\n",
    "\n",
    "import os,sys,inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir) \n",
    "from utils import *\n",
    "from gen_inputs import *\n",
    "from functs_inputs import *\n",
    "from sim_hLN import *\n",
    "from train_hLN import *\n",
    "from init_hLN import *\n",
    "from plot import *\n",
    "from train_run import *\n",
    "\n",
    "matplotlib.rcParams[\"savefig.dpi\"] = 200\n",
    "matplotlib.rcParams[\"legend.frameon\"] = False\n",
    "matplotlib.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1L\n",
    "Jc_1l = np.array([0])\n",
    "# 1N\n",
    "Jc_1n = [0]\n",
    "# 2N\n",
    "Jc_2n = [0, 1, 1]\n",
    "# 3N\n",
    "Jc_3n = [0, 1, 1, 2, 2, 3, 3]\n",
    "# 4N\n",
    "Jc_4n = [0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some realistic inputs\n",
    "X_tot = tf.convert_to_tensor(np.load('../Data/real_inputs.npy'), dtype=tf.float32)  # real inputs made earlier\n",
    "X_e = X_tot[:629] # 629 excitatory inputs, in 13 ensembles\n",
    "X_i = X_tot[629:] # 120 inhibitory inputs, also in 13 ensembles\n",
    "# remember 1st inhibitory inputs is the somatic input - must always go to root subunit\n",
    "inputs=X_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [00:35<00:00, 111.91it/s]\n",
      "100%|██████████| 4000/4000 [00:30<00:00, 131.07it/s]\n",
      "100%|██████████| 4000/4000 [00:26<00:00, 150.74it/s]\n",
      "100%|██████████| 4000/4000 [00:26<00:00, 151.00it/s]\n",
      "100%|██████████| 4000/4000 [00:27<00:00, 145.97it/s]\n",
      "100%|██████████| 4000/4000 [00:28<00:00, 141.21it/s]\n",
      "100%|██████████| 4000/4000 [00:28<00:00, 139.04it/s]\n",
      "100%|██████████| 4000/4000 [00:33<00:00, 118.48it/s]\n",
      "100%|██████████| 4000/4000 [00:31<00:00, 127.50it/s]\n",
      "100%|██████████| 4000/4000 [00:27<00:00, 144.90it/s]\n",
      " 50%|████▉     | 1991/4000 [00:13<00:13, 144.25it/s]"
     ]
    }
   ],
   "source": [
    "# now do multiple simulations for each case\n",
    "Wce_sing, Wci_sing = np.array([np.array([0])]), np.array([np.array([])])\n",
    "hln_test = hLN_Model(Jc=Jc_1l, Wce=Wce_sing, Wci=Wci_sing, sig_on=tf.constant([False]))\n",
    "train_accuracies, test_accuracies, trained_params_list, target_params_list = test_recovery(model=hln_test, inputs=inputs, num_sims=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box plot of recovered accuracies in hLN models\n",
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Boxplot of test and training dataset \\n accuracies after training', fontsize=20)\n",
    "ax.boxplot([train_accuracies, test_accuracies])\n",
    "ax.set_xticklabels(['Training', 'Test'], fontsize=14)\n",
    "ax.set_ylabel(\"Accuracy (%)\")\n",
    "# ax.set_ylim(100)\n",
    "\n",
    "# plt.savefig(\"Figures/1l_accuracies_5attempts_10sims.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_params_1l(trained_params, target_params, name=\"name\", save=False):\n",
    "    \"\"\"create plots to compare trained parameters with target parameters for single subunit linear model.\n",
    "    trained_params and target_params are lists of parameters for multiple recoveries returned by the test_recovery\n",
    "    function.\"\"\"\n",
    "\n",
    "    trained_params, target_params = np.array(trained_params), np.array(target_params)\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2)\n",
    "    fig.set_size_inches(15, 15)\n",
    "\n",
    "    # extract the linear parameters we want for plotting\n",
    "    trained_v0s, target_v0s = trained_params[:, 0], target_params[:, 0]\n",
    "    trained_Wwes, target_Wwes = np.concatenate(trained_params[:, 2]), np.concatenate(target_params[:, 2])\n",
    "    trained_logTaues, target_logTaues = np.concatenate(trained_params[:, 4]), np.concatenate(target_params[:, 4])\n",
    "    trained_logDelays, target_logDelays = np.concatenate(trained_params[:, 7]), np.concatenate(target_params[:, 7]) \n",
    "    \n",
    "    # convert log parameters to normal values\n",
    "    trained_Taues, trained_Delays = np.exp(trained_logTaues), np.exp(trained_logDelays)\n",
    "    target_Taues, target_Delays = np.exp(target_logTaues), np.exp(target_logDelays)\n",
    "    \n",
    "    # store all linear parameters in list\n",
    "    lin_target_params = [target_v0s, target_Wwes, target_Taues, target_Delays]\n",
    "    lin_trained_params = [trained_v0s, trained_Wwes, trained_Taues, trained_Delays]\n",
    "    \n",
    "    param_names = [\"v0\", \"Wwe\", \"Taue\", \"Delay\"]\n",
    "    i=0\n",
    "    for row in range(2):\n",
    "        for col in range(2):\n",
    "            # flatten input parameter arrays for plotting\n",
    "            p_trained, p_target = lin_trained_params[i], lin_target_params[i]\n",
    "\n",
    "            if len(p_trained) > 0:\n",
    "                ax[row, col].scatter(p_target, p_trained)\n",
    "                x = np.linspace(min(p_trained), max(p_trained), 100)\n",
    "                ax[row, col].plot(x, x, color='red', label='Perfect recovery')\n",
    "                ax[row, col].set_xlabel(\"Truth\")\n",
    "                ax[row, col].set_ylabel(\"Recovered\")\n",
    "                ax[row, col].yaxis.set_major_formatter(matplotlib.ticker.FormatStrFormatter('%.3f'))\n",
    "                ax[row, col].xaxis.set_major_formatter(matplotlib.ticker.FormatStrFormatter('%.3f'))\n",
    "                if len(p_trained) > 1:\n",
    "                    var_explained = 1 - ((p_trained - p_target) ** 2).mean() / np.var(p_target)\n",
    "                    ax[row, col].set_title(param_names[i] + f\", ve = {100*var_explained:.2f}%\")\n",
    "                elif len(p_trained) == 1:\n",
    "                    error = np.abs((p_trained[0] - p_target[0]) / p_target[0]) * 100\n",
    "                    ax[row, col].set_title(param_names[i] + f\", error ={error:.2f}%\")\n",
    "                ax[row, col].legend()\n",
    "\n",
    "            i += 1\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(name)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_params_1l(trained_params_list, target_params_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
